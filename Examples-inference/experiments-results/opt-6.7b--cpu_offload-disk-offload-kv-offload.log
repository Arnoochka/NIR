[2025-03-19 17:23:18,338] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/victor/anaconda3/envs/deepspeed/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/victor/anaconda3/envs/deepspeed/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
[2025-03-19 17:23:19,862] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-03-19 17:23:19,862] [INFO] [runner.py:607:main] cmd = /home/victor/anaconda3/envs/deepspeed/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None run_model.py --model facebook/opt-6.7b --batch-size 3 --prompt-len 512 --gen-len 32 --pin-memory 1 --cpu-offload --kv-offload --disk-offload --offload-dir offload
[2025-03-19 17:23:20,989] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/victor/anaconda3/envs/deepspeed/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/victor/anaconda3/envs/deepspeed/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
[2025-03-19 17:23:22,429] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}
[2025-03-19 17:23:22,429] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0
[2025-03-19 17:23:22,429] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2025-03-19 17:23:22,430] [INFO] [launch.py:164:main] dist_world_size=1
[2025-03-19 17:23:22,430] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0
[2025-03-19 17:23:22,430] [INFO] [launch.py:256:main] process 39848 spawned with command: ['/home/victor/anaconda3/envs/deepspeed/bin/python', '-u', 'run_model.py', '--local_rank=0', '--model', 'facebook/opt-6.7b', '--batch-size', '3', '--prompt-len', '512', '--gen-len', '32', '--pin-memory', '1', '--cpu-offload', '--kv-offload', '--disk-offload', '--offload-dir', 'offload']
[2025-03-19 17:23:23,506] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/victor/anaconda3/envs/deepspeed/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/home/victor/anaconda3/envs/deepspeed/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
[2025-03-19 17:23:25,008] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-03-19 17:23:25,008] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/home/victor/anaconda3/envs/deepspeed/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
load model
{'device': 'nvme', 'pin_memory': True, 'nvme_path': '/home/victor/NIR/Examples-inference/zero_inference/offload', 'buffer_count': 2, 'buffer_size': 536870912.0}
[2025-03-19 17:23:26,178] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 1
Installed CUDA version 12.6 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
[2025-03-19 17:23:29,983] [INFO] [utils.py:30:print_object] AsyncPartitionedParameterSwapper:
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   aio_config ................... {'block_size': 16777216, 'queue_depth': 64, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   aio_handle ................... <class 'async_io.aio_handle'>
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   aligned_bytes ................ 1024
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   aligned_elements_per_buffer .. 536870912
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   available_buffer_ids ......... [0, 1]
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   available_numel .............. 0
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   available_params ............. set()
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   dtype ........................ torch.float16
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   elements_per_buffer .......... 536870912
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   id_to_path ................... {}
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   inflight_numel ............... 0
[2025-03-19 17:23:29,983] [INFO] [utils.py:34:print_object]   inflight_params .............. []
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   inflight_swap_in_buffers ..... []
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   invalid_buffer ............... 1.0
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   min_aio_bytes ................ 16777216
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   numel_alignment .............. 512
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   param_buffer_count ........... 2
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   param_id_to_buffer_id ........ {}
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   param_id_to_numel ............ {}
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   param_id_to_swap_buffer ...... {}
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   partitioned_swap_buffer ...... None
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   partitioned_swap_pool ........ None
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   pending_reads ................ 0
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   pending_writes ............... 0
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   reserved_buffer_ids .......... []
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   swap_config .................. device='nvme' nvme_path=PosixPath('/home/victor/NIR/Examples-inference/zero_inference/offload') buffer_count=2 buffer_size=536870912 max_in_cpu=1000000000 pin_memory=True
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   swap_element_size ............ 2
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   swap_folder .................. /home/victor/NIR/Examples-inference/zero_inference/offload/zero_stage_3/float16params/rank0
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   swap_out_params .............. []
[2025-03-19 17:23:29,984] [INFO] [utils.py:34:print_object]   use_gds ...................... False
[2025-03-19 17:23:39,659] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 517, num_elems = 6.86B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:26<00:26, 26.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:34<00:00, 15.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:34<00:00, 17.22s/it]
/home/victor/anaconda3/envs/deepspeed/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-03-19 17:24:14,318] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown
[2025-03-19 17:24:14,319] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 1
[2025-03-19 17:24:14,331] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-03-19 17:24:14,332] [INFO] [logging.py:128:log_dist] [Rank 0] Creating ZeRO Offload
[2025-03-19 17:24:14,443] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-03-19 17:24:14,443] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.77 GB         CA 0.77 GB         Max_CA 1 GB 
[2025-03-19 17:24:14,443] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 5.12 GB, percent = 34.1%
Parameter Offload: Total persistent parameters: 1187840 in 290 params
[2025-03-19 17:24:14,564] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-03-19 17:24:14,564] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.77 GB         Max_CA 1 GB 
[2025-03-19 17:24:14,564] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 5.12 GB, percent = 34.1%
[2025-03-19 17:24:14,565] [INFO] [config.py:1001:print] DeepSpeedEngine configuration:
[2025-03-19 17:24:14,565] [INFO] [config.py:1005:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-03-19 17:24:14,565] [INFO] [config.py:1005:print]   aio_config ................... {'block_size': 16777216, 'queue_depth': 64, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   amp_enabled .................. False
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   amp_params ................... False
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   bfloat16_enabled ............. False
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   bfloat16_immediate_grad_update  False
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   checkpoint_parallel_write_pipeline  False
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   checkpoint_tag_validation_enabled  True
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   checkpoint_tag_validation_fail  False
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7a1b5c66fd50>
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   communication_data_type ...... None
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   curriculum_enabled_legacy .... False
[2025-03-19 17:24:14,566] [INFO] [config.py:1005:print]   curriculum_params_legacy ..... False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   data_efficiency_enabled ...... False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   dataloader_drop_last ......... False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   disable_allgather ............ False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   dump_state ................... False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   dynamic_loss_scale_args ...... None
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   eigenvalue_enabled ........... False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   eigenvalue_gas_boundary_resolution  1
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   eigenvalue_layer_num ......... 0
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   eigenvalue_max_iter .......... 100
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   eigenvalue_stability ......... 1e-06
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   eigenvalue_tol ............... 0.01
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   eigenvalue_verbose ........... False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   elasticity_enabled ........... False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   fp16_auto_cast ............... False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   fp16_enabled ................. True
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   fp16_master_weights_and_gradients  False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   global_rank .................. 0
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   grad_accum_dtype ............. None
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   gradient_accumulation_steps .. 1
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   gradient_clipping ............ 0.0
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   gradient_predivide_factor .... 1.0
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   graph_harvesting ............. False
[2025-03-19 17:24:14,567] [INFO] [config.py:1005:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   initial_dynamic_scale ........ 65536
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   load_universal_checkpoint .... False
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   loss_scale ................... 0
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   memory_breakdown ............. False
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   mics_hierarchial_params_gather  False
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   mics_shard_size .............. -1
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   optimizer_legacy_fusion ...... False
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   optimizer_name ............... None
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   optimizer_params ............. None
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   pld_enabled .................. False
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   pld_params ................... False
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   prescale_gradients ........... False
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   scheduler_name ............... None
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   scheduler_params ............. None
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   seq_parallel_communication_data_type  torch.float32
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   sparse_attention ............. None
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   sparse_gradients_enabled ..... False
[2025-03-19 17:24:14,568] [INFO] [config.py:1005:print]   steps_per_print .............. 2000
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   timers_config ................ enabled=True synchronized=True
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   train_batch_size ............. 3
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   train_micro_batch_size_per_gpu  3
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   use_data_before_expert_parallel_  False
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   use_node_local_storage ....... False
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   wall_clock_breakdown ......... False
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   weight_quantization_config ... None
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   world_size ................... 1
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   zero_allow_untested_optimizer  False
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='nvme', nvme_path=PosixPath('/home/victor/NIR/Examples-inference/zero_inference/offload'), buffer_count=2, buffer_size=536870912, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=33554432 param_persistence_threshold=4096 model_persistence_threshold=9223372036854775807 max_live_parameters=33554432 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   zero_enabled ................. True
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   zero_force_ds_cpu_optimizer .. True
[2025-03-19 17:24:14,569] [INFO] [config.py:1005:print]   zero_optimization_stage ...... 3
[2025-03-19 17:24:14,569] [INFO] [config.py:991:print_user_config]   json = {
    "fp16": {
        "enabled": true
    }, 
    "bf16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 3, 
        "stage3_prefetch_bucket_size": 3.355443e+07, 
        "stage3_param_persistence_threshold": 4.096000e+03, 
        "stage3_max_live_parameters": 3.355443e+07, 
        "offload_param": {
            "device": "nvme", 
            "pin_memory": true, 
            "nvme_path": "/home/victor/NIR/Examples-inference/zero_inference/offload", 
            "buffer_count": 2, 
            "buffer_size": 5.368709e+08
        }
    }, 
    "steps_per_print": 2.000000e+03, 
    "train_batch_size": 3, 
    "wall_clock_breakdown": false, 
    "aio": {
        "block_size": 1.677722e+07, 
        "queue_depth": 64, 
        "thread_count": 8, 
        "use_gds": false, 
        "single_submit": false, 
        "overlap_events": true
    }
}
model.config = OPTConfig {
  "_name_or_path": "facebook/opt-6.7b",
  "_remove_final_layer_norm": false,
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
    "OPTForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 2,
  "do_layer_norm_before": true,
  "dropout": 0.1,
  "enable_bias": true,
  "eos_token_id": 2,
  "ffn_dim": 16384,
  "hidden_size": 4096,
  "init_std": 0.02,
  "layer_norm_elementwise_affine": true,
  "layerdrop": 0.0,
  "max_position_embeddings": 2048,
  "model_type": "opt",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "pad_token_id": 1,
  "prefix": "</s>",
  "torch_dtype": "float16",
  "transformers_version": "4.33.0.dev0",
  "use_cache": true,
  "vocab_size": 50272,
  "word_embed_proj_dim": 4096
}

benchmark, prompt_len = 512, execute_gen_len = 32, input_ids.shape = torch.Size([3, 512])
token_latency=[7.293515682220459, 5.053404331207275, 5.021448373794556, 5.022504806518555, 5.034446477890015, 5.013979196548462, 5.017314672470093, 5.016512870788574, 5.019129753112793, 5.021639823913574, 5.039419412612915, 5.0174360275268555, 5.032248020172119, 5.031316757202148, 5.0301289558410645, 5.029689788818359, 5.030039548873901, 5.047903060913086, 5.024278879165649, 5.020409822463989, 5.024277687072754, 5.04099178314209, 5.039159774780273, 5.039862155914307, 5.03423285484314, 5.028913497924805, 5.017378091812134, 5.0201499462127686, 5.033297538757324, 5.023081064224243, 5.0201568603515625, 5.025008916854858]
token_latency=[5.437441349029541, 5.023205518722534, 5.025784492492676, 5.0243239402771, 5.023827075958252, 5.032345771789551, 5.038636684417725, 5.0361106395721436, 5.0390918254852295, 5.016368389129639, 5.039841175079346, 5.023558616638184, 5.021836042404175, 5.0207154750823975, 5.02568507194519, 5.0232462882995605, 5.022640943527222, 5.021679878234863, 5.02863883972168, 5.027646780014038, 5.03239107131958, 5.0275046825408936, 5.01942253112793, 5.030294418334961, 5.024177551269531, 5.029809951782227, 5.032267093658447, 5.030146360397339, 5.020960569381714, 5.021966218948364, 5.038318872451782, 5.027267694473267]
token_latency=[5.439209938049316, 5.020832538604736, 5.031666040420532, 5.03129506111145, 5.036122798919678, 5.024919509887695, 5.018470287322998, 5.023431301116943, 5.030343532562256, 5.02198600769043, 5.035508155822754, 5.04732346534729, 5.036237955093384, 5.03208327293396, 5.031372547149658, 5.0324013233184814, 5.097503900527954, 5.098272085189819, 5.049463748931885, 5.032990217208862, 5.044426202774048, 5.035785913467407, 5.036406517028809, 5.035142183303833, 5.052052974700928, 5.0427632331848145, 5.0379157066345215, 5.033490896224976, 5.0209386348724365, 5.030823230743408, 5.020609378814697, 5.0225512981414795]
Summary:
costs = [163.26613653200002, 161.3022422869999, 161.59971183100015], prefill_timings = [7.289947032928467, 5.4371421337127686, 5.438823699951172]
Outputs:
----------------------------------------------------------------------
0: Paris is the capital city of France and the most visited city in the world. It is the most visited city in the world, with more than 30 million visitors each year. Paris is the
----------------------------------------------------------------------
1: Paris is the capital city of France and the most visited city in the world. It is the most visited city in the world, with more than 30 million visitors each year. Paris is the
----------------------------------------------------------------------
2: Paris is the capital city of France and the most visited city in the world. It is the most visited city in the world, with more than 30 million visitors each year. Paris is the
----------------------------------------------------------------------

model size: 12.386 GB	cache size: 0.797 GB	hidden size (p): 0.012 GB
peak gpu mem: 0.549 GB	prefill latency: 5.439 s	prefill throughput: 282.414 token/s
decode latency: 156.161 s	decode throughput: 0.596 token/s
total latency: 161.600 s	total throughput: 0.594 token/s
[rank0]:[W319 17:32:21.708196167 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-03-19 17:32:24,513] [INFO] [launch.py:351:main] Process 39848 exits successfully.
