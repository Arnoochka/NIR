deepspeed --num_gpus 1 main.py >> logger.log 2>&1
[2025-03-18 17:01:40,202] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-18 17:01:42,474] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-03-18 17:01:42,475] [INFO] [runner.py:607:main] cmd = /home/victor/anaconda3/envs/deepspeed/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None main.py --cpu-offload
[2025-03-18 17:01:43,705] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-18 17:01:45,432] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}
[2025-03-18 17:01:45,433] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0
[2025-03-18 17:01:45,433] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2025-03-18 17:01:45,433] [INFO] [launch.py:164:main] dist_world_size=1
[2025-03-18 17:01:45,433] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0
[2025-03-18 17:01:45,433] [INFO] [launch.py:256:main] process 46117 spawned with command: ['/home/victor/anaconda3/envs/deepspeed/bin/python', '-u', 'main.py', '--local_rank=0', '--cpu-offload']
[2025-03-18 17:01:46,596] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Device set to use cuda:0
[2025-03-18 17:01:50,892] [INFO] [logging.py:128:log_dist] [Rank -1] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown
[2025-03-18 17:01:50,892] [INFO] [logging.py:128:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2025-03-18 17:01:50,909] [INFO] [logging.py:128:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1280, 'intermediate_size': 5120, 'heads': 20, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000, 'invert_mask': True}
Using /home/victor/.cache/torch_extensions/py313_cu124 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/victor/.cache/torch_extensions/py313_cu124/transformer_inference/build.ninja...
/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.011439085006713867 seconds
Traceback (most recent call last):
  File "/home/victor/NIR/single-gpu/main.py", line 13, in <module>
    generator.model = deepspeed.init_inference(generator.model,
                      ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
                                               tensor_parallel={"tp_size": world_size},
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                                               dtype=torch.float,
                                               ^^^^^^^^^^^^^^^^^^
                                               replace_with_kernel_inject=True)
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/__init__.py", line 364, in init_inference
    engine = InferenceEngine(model, config=ds_inference_config)
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/inference/engine.py", line 154, in __init__
    self._apply_injection_policy(config)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/inference/engine.py", line 388, in _apply_injection_policy
    replace_transformer_layer(client_module, self.module, checkpoint, config, self.config)
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/module_inject/replace_module.py", line 400, in replace_transformer_layer
    replaced_module = replace_module(model=model,
                                     orig_class=orig_layer_impl,
                                     replace_fn=replace_fn,
                                     _replace_policy=config.injection_policy_tuple)
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/module_inject/replace_module.py", line 653, in replace_module
    replaced_module, _ = _replace_module(model, policy, state_dict=sd)
                         ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/module_inject/replace_module.py", line 713, in _replace_module
    _, layer_id = _replace_module(child,
                  ~~~~~~~~~~~~~~~^^^^^^^
                                  policies,
                                  ^^^^^^^^^
    ...<3 lines>...
                                  level_id=level_id + 1,
                                  ^^^^^^^^^^^^^^^^^^^^^^
                                  state_dict=state_dict)
                                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/module_inject/replace_module.py", line 713, in _replace_module
    _, layer_id = _replace_module(child,
                  ~~~~~~~~~~~~~~~^^^^^^^
                                  policies,
                                  ^^^^^^^^^
    ...<3 lines>...
                                  level_id=level_id + 1,
                                  ^^^^^^^^^^^^^^^^^^^^^^
                                  state_dict=state_dict)
                                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/module_inject/replace_module.py", line 689, in _replace_module
    replaced_module = policies[child.__class__][0](child,
                                                   policies[child.__class__][-1],
                                                   layer_id,
                                                   prefix=prefix + name,
                                                   state_dict=state_dict)
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/module_inject/replace_module.py", line 327, in replace_fn
    new_module = replace_with_policy(child,
                                     _policy,
                                     config.triangular_masking,
                                     inference=True,
                                     layer_id=layer_id)
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/module_inject/replace_module.py", line 248, in replace_with_policy
    _container.create_module()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/module_inject/containers/gpt2.py", line 20, in create_module
    self.module = DeepSpeedGPTInference(_config, mp_group=self.mp_group)
                  ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/model_implementations/transformers/ds_gpt.py", line 20, in __init__
    super().__init__(config, mp_group, quantize_scales, quantize_groups, merge_count, mlp_extra_grouping)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/model_implementations/transformers/ds_transformer.py", line 74, in __init__
    self.mlp = DeepSpeedMLP(self.config, mp_group, quantize_scales, quantize_groups, merge_count,
               ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                            mlp_extra_grouping)
                            ^^^^^^^^^^^^^^^^^^^
  File "/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/deepspeed/ops/transformer/inference/ds_mlp.py", line 56, in __init__
    self.output_w = nn.Parameter(torch.empty(self.intm_o_sz_per_partition,
                                 ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                                             self.config.hidden_size,
                                             ^^^^^^^^^^^^^^^^^^^^^^^^
                                             dtype=data_type,
                                             ^^^^^^^^^^^^^^^^
                                             device=device),
                                             ^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 7.56 MiB is free. Including non-PyTorch memory, this process has 3.68 GiB memory in use. Of the allocated memory 3.53 GiB is allocated by PyTorch, and 82.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-03-18 17:01:52,436] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 46117
[2025-03-18 17:01:52,436] [ERROR] [launch.py:325:sigkill_handler] ['/home/victor/anaconda3/envs/deepspeed/bin/python', '-u', 'main.py', '--local_rank=0', '--cpu-offload'] exits with return code = 1
