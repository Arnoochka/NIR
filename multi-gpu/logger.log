deepspeed --num_gpus 2 main.py >> logger.log 2>&1
[2025-03-12 17:09:13,362] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-12 17:09:16,704] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-03-12 17:09:16,704] [INFO] [runner.py:607:main] cmd = /home/victor/anaconda3/envs/deepspeed/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None main.py
[2025-03-12 17:09:18,657] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-12 17:09:21,480] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1]}
[2025-03-12 17:09:21,480] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=2, node_rank=0
[2025-03-12 17:09:21,480] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2025-03-12 17:09:21,480] [INFO] [launch.py:164:main] dist_world_size=2
[2025-03-12 17:09:21,481] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1
[2025-03-12 17:09:21,483] [INFO] [launch.py:256:main] process 11851 spawned with command: ['/home/victor/anaconda3/envs/deepspeed/bin/python', '-u', 'main.py', '--local_rank=0']
[2025-03-12 17:09:21,485] [INFO] [launch.py:256:main] process 11852 spawned with command: ['/home/victor/anaconda3/envs/deepspeed/bin/python', '-u', 'main.py', '--local_rank=1']
[2025-03-12 17:09:23,684] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-12 17:09:23,748] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Device set to use cuda:0
Device set to use cuda:1
[2025-03-12 17:09:35,332] [INFO] [logging.py:128:log_dist] [Rank -1] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown
[2025-03-12 17:09:35,334] [INFO] [logging.py:128:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2025-03-12 17:09:35,342] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-03-12 17:09:35,342] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-03-12 17:09:36,843] [INFO] [logging.py:128:log_dist] [Rank -1] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown
[2025-03-12 17:09:36,922] [INFO] [logging.py:128:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2025-03-12 17:09:36,926] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-03-12 17:09:36,964] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1280, 'intermediate_size': 5120, 'heads': 20, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 2, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000, 'invert_mask': True}
Using /home/victor/.cache/torch_extensions/py313_cu118 as PyTorch extensions root...
Using /home/victor/.cache/torch_extensions/py313_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/victor/.cache/torch_extensions/py313_cu118/transformer_inference/build.ninja...
/home/victor/anaconda3/envs/deepspeed/lib/python3.13/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module transformer_inference...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.023026704788208008 seconds
Loading extension module transformer_inference...
Time to load transformer_inference op: 0.1084444522857666 seconds
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
------------------------------------------------------
Free memory : 3.139221 (GigaBytes)  
Total memory: 7.919250 (GigaBytes)  
Requested memory: 0.263672 (GigaBytes) 
Setting maximum total tokens (input + output) to 1024 
WorkSpace: 0x720118000000 
------------------------------------------------------
[{'generated_text': "DeepSpeed is based only on the GPU's core and not the CPU core. This means it might be faster for performance in some cases, but there might be some performance drops due to the CPU core. There might be a big improvement in CPU efficiency"}]
[{'generated_text': "DeepSpeed is based only on the GPU's core and not the CPU core. This means it might be faster for performance in some cases, but there might be some performance drops due to the CPU core. There might be a big improvement in CPU efficiency"}]
[rank0]:[W312 17:09:39.510595415 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-03-12 17:09:42,495] [INFO] [launch.py:351:main] Process 11852 exits successfully.
[2025-03-12 17:09:42,497] [INFO] [launch.py:351:main] Process 11851 exits successfully.
