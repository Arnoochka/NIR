{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MindSpore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP and Functional paradigms in MindSpore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MindStore можно писать в ООП, функциональном и оба сразу стилях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "from mindspore import value_and_grad\n",
    "import mindspore.numpy as mnp\n",
    "from mindspore import grad, Tensor, Parameter\n",
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import mindspore as ms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function mindspore.ops.composite.base._Grad.__call__.<locals>.after_grad(*args, **kwargs)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TrainOneStepCell(nn.Cell): # классы всегда должны наследоваться от nn.Cell\n",
    "    def __init__(self, network, optimizer):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.optimizer = optimizer\n",
    "        self.grad_fn = value_and_grad(self.network, None, self.optimizer.parameters)\n",
    "\n",
    "    def construct(self, *inputs):\n",
    "        loss, grads = self.grad_fn(*inputs)\n",
    "        self.optimizer(grads)\n",
    "        return loss\n",
    "\n",
    "network = nn.Dense(5, 3)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "network_with_loss = nn.WithLossCell(network, loss_fn)\n",
    "optimizer = nn.SGD(network.trainable_params(), 0.001)\n",
    "trainer = TrainOneStepCell(network_with_loss, optimizer)\n",
    "trainer.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[1], dtype=Float64, value= [ 4.19974342e-01]),\n",
       " Tensor(shape=[1], dtype=Float64, value= [-6.39700008e-01]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mindspore.numpy as mnp\n",
    "from mindspore import grad, Tensor\n",
    "\n",
    "grad_tanh = grad(mnp.tanh)\n",
    "point = Tensor(np.array([1.0]))\n",
    "\n",
    "grad_tanh(point), grad(grad_tanh)(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Автоматическое дифференцирование\n",
    "\n",
    "**Автоматическое дифференцирование**- метод дифференцирования функций, при которым мы не получаем аналитическое выражение, но получаем точно значение градиента в нужной точки. Работает он при условии того, у всех функций (в том числе и вложенных) существует значение в выбранной точке. Существует 2 режима этого дифференцирования: **прямой** и **обратный**. Функция grad (она в MindStore вычисляет градиент) работает во втором режиме. (как я понял, можно переключиться и в прямой режим, ожнако это лучше делать для сетей, у которых меньше входов, чем выходов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![reverse_mode](./pictures/reverse_mode_AD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic and Static Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4. 10. 18.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(40257,7edc4e585240,python):2024-10-09-17:43:09.994.803 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_40257/3879228493.py]\n"
     ]
    }
   ],
   "source": [
    "ms.set_context(mode=ms.GRAPH_MODE, device_target=\"CPU\") \n",
    "'''\n",
    "это означает, что используется статических граф и\n",
    "все вычисление происходят на CPU\n",
    "'''\n",
    "\n",
    "class Net(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.mul = ops.Mul()\n",
    "\n",
    "    def construct(self, x, y):\n",
    "        return self.mul(x, y)\n",
    "\n",
    "x = ms.Tensor(np.array([1.0, 2.0, 3.0]).astype(np.float32))\n",
    "y = ms.Tensor(np.array([4.0, 5.0, 6.0]).astype(np.float32))\n",
    "\n",
    "net = Net()\n",
    "print(net(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[2. 2. 2. 2.]\n",
      "   [2. 2. 2. 2.]\n",
      "   [2. 2. 2. 2.]]\n",
      "\n",
      "  [[2. 2. 2. 2.]\n",
      "   [2. 2. 2. 2.]\n",
      "   [2. 2. 2. 2.]]]]\n"
     ]
    }
   ],
   "source": [
    "ms.set_context(mode=ms.PYNATIVE_MODE, device_target=\"GPU\")\n",
    "x = ms.Tensor(np.ones([1, 2, 3, 4]).astype(np.float32))\n",
    "y = ms.Tensor(np.ones([1, 2, 3, 4]).astype(np.float32))\n",
    "output = ops.add(x, y)\n",
    "print(output.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного о том, как это работает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, when the Python interface ops.add(x, y) is called, the Python interface call is called to the C++ layer of the framework via Pybind11, and converted to C++ call. Then the framework will select the corresponding hardware device according to the device_target set by the users, and execute the add operation on that hardware device.\n",
    "\n",
    "From the above principle, we can see that in PyNative mode, Python script code will be executed according to Python syntax, and the execution process involves MindSpore's API, which will be accelerated by executing on different hardware according to user settings. Therefore, in PyNative mode, users can use Python syntax and debugging methods at will, for example, you can use common IDEs such as PyCharm and VS Code to debug code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Комбинировние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddMulMul(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(AddMulMul, self).__init__()\n",
    "        self.param = ms.Parameter(ms.Tensor(0.5, ms.float32))\n",
    "\n",
    "    @ms.jit\n",
    "    def construct(self, x):\n",
    "        x = x + x\n",
    "        x = x * self.param\n",
    "        x = x * x\n",
    "        return x\n",
    "\n",
    "class CellCallSingleCell(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(CellCallSingleCell, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 2, kernel_size=2, stride=1, padding=0, weight_init=\"ones\", pad_mode=\"valid\")\n",
    "        self.bn = nn.BatchNorm2d(2, momentum=0.99, eps=0.00001, gamma_init=\"ones\")\n",
    "        self.relu = nn.ReLU()\n",
    "        self.add_mul_mul = AddMulMul()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.add_mul_mul(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "ms.set_context(mode=ms.PYNATIVE_MODE, device_target=\"GPU\")\n",
    "inputs = ms.Tensor(np.ones([1, 1, 2, 2]).astype(np.float32))\n",
    "net = CellCallSingleCell()\n",
    "out = net(inputs)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообщем, графы можно комбинировать. Для динамичесих графов используется статическая компиляция. Для статичесих - JIT-компиляция. Там, где подписано JIT - статический вычислительный граф."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Graph Dynamic Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Менее проще я пока не могу описать: https://www.mindspore.cn/docs/en/r2.3.1/design/dynamic_shape.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
