{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Automatic Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У MindSpore есть распределенные операторы и она умеет работать с распределенными тензорами. Пользователю о том, как это работает внутри думать не приходится. При этом MindSpore имеет 3 стратегии для распределения (как я понял, MindSPore может для каждого случая автоматически подбирать подходящую, хотя можно и задать самому). Их можно рассмотреть на примере умножения Тензора input на Тензор weight. \n",
    "\n",
    "1) **data parallelism**. При этой стратегии проиходит разрез input, weights не разрезается, задается так: `strategy=((2^N, 1, 1),(1, 1, 1))`*\n",
    "2) **model parallelism**. При этой стратегии наоборот происходит разрез weights. Задается так: `strategy=((1, 1, 1),(2^N, 1, 1))`*\n",
    "3) **mixed parallelism**. Разрезается и то, и другое. Задается так: `strategy=((2^N, 1, 1),(1, 1, 2^N))`*\n",
    "\n",
    "На основе стратегии шардов в распределенном операторе определяется метод модели распределения входного и выходного тензора оператора. Распределенная модель состоит из      `device_matrix` (то, как происходит распределение), `tensor_shape` (рахмерность тензора), `tensor_map`(отношение между размерностями устройства и тензора). Распределенный оператор далее определяет, следует ли вставлять в граф дополнительные вычислительные и коммуникационные операции в соответствии с моделью тензорного распределения, чтобы обеспечить корректность логики работы оператора. (Суть этого предложение можно понять, если прочитать следующий пункт)\n",
    "\n",
    "\\* **Замечание:** 2^N, ибо MindSpore исходит из 2-х принципов: principle of base-2 and uniform distribution. Кортежах под цифрами обозначается, что можно делить и на сколько."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensor_parallel](../pictures/Tensor_parallel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"DistributedOperators\" style=\"text-decoration: none; color: #cccccc;\">Distributed operators</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "from mindspore import ops\n",
    "import mindspore as ms\n",
    "import numpy as np\n",
    "from mindspore.communication import init\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE, device_target=\"GPU\")\n",
    "ms.set_auto_parallel_context(parallel_mode=ms.ParallelMode.SEMI_AUTO_PARALLEL, device_num=4)\n",
    "\n",
    "init()\n",
    "\n",
    "class DenseMatMulNet(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(DenseMatMulNet, self).__init__()\n",
    "        self.matmul1 = ops.MatMul().shard(((4, 1), (1, 1)))\n",
    "        self.matmul2 = ops.MatMul().shard(((1, 1), (1, 4)))\n",
    "        \n",
    "    def construct(self, x, w, v):\n",
    "        y = self.matmul1(x, w)\n",
    "        print(\"y=\", y)\n",
    "        z = self.matmul2(y, v)\n",
    "        print(\"z=\", z)\n",
    "        return z\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    net = DenseMatMulNet()\n",
    "    matrix = np.array([\n",
    "        [1, 1, 1, 1],\n",
    "        [1, 1, 1, 1],\n",
    "        [1, 1, 1, 1],\n",
    "        [1, 1, 1, 1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    result = net(ms.Tensor(matrix), ms.Tensor(matrix), ms.Tensor(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{pmatrix}\n",
    "    X_1\\\\\n",
    "    X_2\\\\\n",
    "    X_3\\\\\n",
    "    X_4\n",
    "\\end{pmatrix} * W = \n",
    "\\begin{pmatrix}\n",
    "    Y_1\\\\\n",
    "    Y_2\\\\\n",
    "    Y_3\\\\\n",
    "    Y_4\n",
    "\\end{pmatrix} => AllGather => Y * \\begin{pmatrix} V_1&V_2&V_3&V_4 \\end{pmatrix} = \\begin{pmatrix} Z_1 &Z_2 & Z_3 & Z_4 \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "import mindspore.dataset as ds\n",
    "from mindspore import nn, ops\n",
    "from mindspore.communication import init\n",
    "from mindspore.common.initializer import initializer\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE)\n",
    "ms.set_context(max_device_memory=\"28GB\")\n",
    "ms.set_auto_parallel_context(parallel_mode=ms.ParallelMode.SEMI_AUTO_PARALLEL)\n",
    "init()\n",
    "ms.set_seed(1)\n",
    "\n",
    "class Network(nn.Cell):\n",
    "    \"\"\"Network\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = ops.Flatten()\n",
    "        self.fc1_weight = ms.Parameter(initializer(\"normal\", [28*28, 512], ms.float32))\n",
    "        self.fc2_weight = ms.Parameter(initializer(\"normal\", [512, 512], ms.float32))\n",
    "        self.fc3_weight = ms.Parameter(initializer(\"normal\", [512, 10], ms.float32))\n",
    "        self.matmul1 = ops.MatMul()\n",
    "        self.relu1 = ops.ReLU()\n",
    "        self.matmul2 = ops.MatMul()\n",
    "        self.relu2 = ops.ReLU()\n",
    "        self.matmul3 = ops.MatMul()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.matmul1(x, self.fc1_weight)\n",
    "        x = self.relu1(x)\n",
    "        x = self.matmul2(x, self.fc2_weight)\n",
    "        x = self.relu2(x)\n",
    "        logits = self.matmul3(x, self.fc3_weight)\n",
    "        return logits\n",
    "\n",
    "net = Network()\n",
    "net.matmul1.shard(((2, 4), (4, 1)))\n",
    "net.relu1.shard(((4, 1),)) \n",
    "net.matmul2.shard(((1, 8), (8, 1)))\n",
    "net.relu2.shard(((8, 1),))\n",
    "\n",
    "def create_dataset(batch_size):\n",
    "    \"\"\"create dataset\"\"\"\n",
    "    dataset_path = os.getenv(\"DATA_PATH\")\n",
    "    dataset = ds.MnistDataset(dataset_path)\n",
    "    image_transforms = [\n",
    "        ds.vision.Rescale(1.0 / 255.0, 0),\n",
    "        ds.vision.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "        ds.vision.HWC2CHW()\n",
    "    ]\n",
    "    label_transform = ds.transforms.TypeCast(ms.int32)\n",
    "    dataset = dataset.map(image_transforms, 'image')\n",
    "    dataset = dataset.map(label_transform, 'label')\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "data_set = create_dataset(32)\n",
    "optimizer = nn.SGD(net.trainable_params(), 1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def forward_fn(data, target):\n",
    "    \"\"\"forward propagation\"\"\"\n",
    "    logits = net(data)\n",
    "    loss = loss_fn(logits, target)\n",
    "    return loss, logits\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, net.trainable_params(), has_aux=True)\n",
    "\n",
    "@ms.jit\n",
    "def train_step(inputs, targets):\n",
    "    \"\"\"train_step\"\"\"\n",
    "    (loss_value, _), grads = grad_fn(inputs, targets)\n",
    "    optimizer(grads)\n",
    "    return loss_value\n",
    "\n",
    "for epoch in range(10):\n",
    "    i = 0\n",
    "    for image, label in data_set:\n",
    "        loss_output = train_step(image, label)\n",
    "        if i % 10 == 0:\n",
    "            print(\"epoch: %s, step: %s, loss is %s\" % (epoch, i, loss_output))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Matmul1\n",
    "\n",
    "$$ \n",
    "\\begin{pmatrix}\n",
    "    X_{11} & X_{12} & X_{13} & X_{14}\\\\\n",
    "    X_{21} & X_{22} & X_{23} & X_{24}\n",
    "\\end{pmatrix} * \\begin{pmatrix} W_{1} \\\\ W_{2} \\\\ W_{3} \\\\ W_{4} \\end{pmatrix} =(AllReduce)= \\begin{pmatrix} \\sum\\limits_{i=1}^4X_{1i}W_i  \\\\ \\sum\\limits_{i=1}^4X_{1i}W_i \\end{pmatrix} = \\begin{pmatrix} Y_1 \\\\ Y_2 \\end{pmatrix} = \n",
    "$$\n",
    "\n",
    "### 2) ReLU1\n",
    "$$\n",
    "Y_i = \\begin{pmatrix}\n",
    "    Y_{i1} \\\\ Y_{i2} \\\\ Y_{i3} \\\\ Y_{i4}\n",
    "\\end{pmatrix} = (ReLU) = \\begin{pmatrix} Y_{i1}' \\\\ Y_{i2}' \\\\ Y_{i3}' \\\\ Y_{i4}'\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**Замечание:** Параллельно задействуется 8 видеокарт, так $i = 1, 2$\n",
    "\n",
    "### 3) Matmul2\n",
    "$$\n",
    "=\\begin{pmatrix}\n",
    "    X_1 & X_2 & X_3 & X_4 & X_5 & X_6 & X_7 & X_8\n",
    "\\end{pmatrix} * \\begin{pmatrix}\n",
    "    V_1 \\\\ V_2 \\\\ V_3 \\\\ V_4 \\\\ V_5 \\\\ V_6 \\\\ V_7 \\\\ V_8\n",
    "\\end{pmatrix} =(AllReduce)= \\sum\\limits_{i=1}^8 X_i*V_i = Y\n",
    "$$\n",
    "\n",
    "### 4) ReLU2\n",
    "$$\n",
    "Y = \\begin{pmatrix}\n",
    "    Y_1 \\\\ Y_2 \\\\ Y_3 \\\\ Y_4 \\\\ Y_5 \\\\ Y_6 \\\\ Y_7 \\\\ Y_8\n",
    "\\end{pmatrix} = (ReLU) = \\begin{pmatrix}\n",
    "    Y_1' \\\\ Y_2' \\\\ Y_3' \\\\ Y_4' \\\\ Y_5' \\\\ Y_6' \\\\ Y_7' \\\\ Y_8'\n",
    "\\end{pmatrix} = Y'\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Операторы, поддерживающие параллелизм\n",
    "[все операторы, поддерживающие параллелизм](https://www.mindspore.cn/docs/en/r2.2/note/operator_list_parallel.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AllReduce**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindspore.communication import init, get_rank\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "\n",
    "init()\n",
    "class Net(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.all_reduce_sum = ops.AllReduce(ops.ReduceOp.SUM, group=\"nccl_world_group\")\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.all_reduce_sum(x)\n",
    "\n",
    "value = get_rank()\n",
    "input_x = ms.Tensor(np.array([[value]]).astype(np.float32))\n",
    "net = Net()\n",
    "output = net(input_x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AllReduce](../pictures/OperatorParallelism/AllRefuce.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AllGather**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "from mindspore.communication import init, get_rank\n",
    "import mindspore as ms\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE)\n",
    "init()\n",
    "class Net(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.all_gather = ops.AllGather()\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.all_gather(x)\n",
    "\n",
    "value = get_rank()\n",
    "input_x = ms.Tensor(np.array([[value]]).astype(np.float32))\n",
    "net = Net()\n",
    "output = net(input_x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AllGather](../pictures/OperatorParallelism/AllGather.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReduceScatter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "from mindspore.communication import init, get_rank\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import numpy as np\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE)\n",
    "init()\n",
    "class Net(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.reduce_scatter = ops.ReduceScatter(ops.ReduceOp.SUM)\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.reduce_scatter(x)\n",
    "\n",
    "input_x = ms.Tensor(np.array([[0], [1], [2], [3]]).astype(np.float32))\n",
    "net = Net()\n",
    "output = net(input_x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "операция сначала суммирует входные данные каждой карты, а затем разбивает данные на количество карт и распределяет данные по соответствующей карте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ReduceScatter](../pictures/OperatorParallelism/ReduceScatter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Broadcast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "from mindspore.communication import init\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import numpy as np\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE)\n",
    "init()\n",
    "class Net(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.broadcast = ops.Broadcast(0)\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.broadcast((x,))\n",
    "\n",
    "input_x = ms.Tensor(np.array([[0]]).astype(np.int32))\n",
    "net = Net()\n",
    "output = net(input_x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Broadcast](../pictures/OperatorParallelism/Broadcast.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NeighborExchange**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "from mindspore.communication import init\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import numpy as np\n",
    "\n",
    "class Net0(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net0, self).__init__()\n",
    "        self.neighbor_exchange = ops.NeighborExchange(send_rank_ids=[1], recv_rank_ids=[1], recv_shapes=([2, 2],), send_shapes=([3, 3],), recv_type=ms.float32)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.neighbor_exchange((x,))\n",
    "        return out[0]\n",
    "\n",
    "class Net1(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.neighbor_exchange = ops.NeighborExchange(send_rank_ids=[0], recv_rank_ids=[0], recv_shapes=([3, 3],), send_shapes=([2, 2],), recv_type=ms.float32)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.neighbor_exchange((x,))\n",
    "        return out[0]\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE)\n",
    "init()\n",
    "rank_id = int(os.getenv(\"RANK_ID\"))\n",
    "if (rank_id % 2 == 0):\n",
    "    input_x = ms.Tensor(np.ones([3, 3]), dtype = ms.float32)\n",
    "    net = Net0()\n",
    "    output = net(input_x)\n",
    "    print(output)\n",
    "else:\n",
    "    input_x = ms.Tensor(np.ones([2, 2]) * 2, dtype = ms.float32)\n",
    "    net = Net1()\n",
    "    output = net(input_x)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Операция `NeighborExchange` предоставит набор данных, которые будут отправлены на каждую из других конкретных карт при получении данных с\n",
    "конкретной карты. Например, на приведенном ниже рисунке ранг 0 отправляет тензор с формой [16,16] в ранг 1 и получает тензор с формой\n",
    "[32,32] из ранга 1. ранг 1 отправляет тензор с формой [32,32] в ранг 0 и получает тензор с формой [16,16] из ранга 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NeighborExchange](../pictures/OperatorParallelism/NeighborExchange.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NeighborExchangeV2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "from mindspore.communication import init\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import numpy as np\n",
    "\n",
    "class Net0(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net0, self).__init__()\n",
    "        self.neighbor_exchangev2 = ops.NeighborExchangeV2(send_rank_ids=[-1, -1, -1, -1, 1, -1, -1, -1], send_lens=[0, 1, 0, 0], recv_rank_ids=[-1, -1, -1, -1, 1, -1, -1, -1], recv_lens=[0, 1, 0, 0], data_format=\"NCHW\")\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.neighbor_exchangev2(x)\n",
    "        return out\n",
    "\n",
    "class Net1(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.neighbor_exchangev2 = ops.NeighborExchangeV2(send_rank_ids=[0, -1, -1, -1, -1, -1, -1, -1], send_lens=[1, 0, 0, 0], recv_rank_ids=[0, -1, -1, -1, -1, -1, -1, -1], recv_lens=[1, 0, 0, 0], data_format=\"NCHW\")\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.neighbor_exchangev2(x)\n",
    "        return out\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE)\n",
    "init()\n",
    "rank_id = int(os.getenv(\"RANK_ID\"))\n",
    "if (rank_id % 2 == 0):\n",
    "    input_x = ms.Tensor(np.ones([1, 1, 2, 2]), dtype = ms.float32)\n",
    "    net = Net0()\n",
    "    output = net(input_x)\n",
    "    print(output)\n",
    "else:\n",
    "    input_x = ms.Tensor(np.ones([1, 1, 2, 2]) * 2, dtype = ms.float32)\n",
    "    net = Net1()\n",
    "    output = net(input_x)\n",
    "    print(output)\n",
    "    \n",
    "'''\n",
    "мы используем оператора NeighborExchangeV2 для обмена данными между картой 0 и картой 1,\n",
    "отправляя данные, указанные под картой 0, на карту 1 и получая данные с карты 1, прошитой ниже.\n",
    "Карта 1 отправляет верхнюю часть данных на карту 0 и получает данные с карты 0, прошитой сверху. Наконец, каждая карта выводит полученные данные.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Операция `NeighborExchangeV2` отправляет часть данных из тензора на окружающие 8 карт в соответствии с настройками атрибута и\n",
    "получает данные с окружающих 8 карт и объединяет их в новый тензор, который часто используется в сценариях, когда большой тензор\n",
    "разбивается на несколько карт для распределенных сверточных операций. Атрибуты send_rank_ids и recv_rank_ids представляют собой 8 чисел, соответственно,\n",
    "указывающих на отправку/получение идентификатора ранжирования в 8 направлениях, а заполнение -1 означает отсутствие отправки/получения. \n",
    "Атрибуты send_lens и recv_lens - это четыре числа, которые представляют длину передачи/приема в\n",
    "четырех направлениях [вверху, внизу, слева, справа] соответственно. Например, на рисунке 1 ниже показан пример с 16 карточками, в качестве примера возьмем 10-й ранг\n",
    ", установим send_rank_ids=[6,7,11,15,14,13,9,5], данные 10-го ранга будут вырезаны и отправлены в rank. 5, 6, 7, 11, 15, 14, 13, 9 соответственно,\n",
    "например, красный цвет на рисунке переводится в ранг 5, красный, желтый и синий - в ранг 6, синий - в ранг 7 и т.д. Установка recv_rank_ids=[6,7,11,15,14,13,9,5],\n",
    "в то же время rank10 получает некоторые данные с каждой из этих карточек, прошитых в соответствующем направлении, для формирования нового тензорного\n",
    "вывода, как показано на рисунке с rank10 и светло-зеленой частью.\n",
    "\n",
    "**Замечание:** Как я понял, мы по сути создаем определенную топологию наших карт для последующей передачи на них определенных частей тензора, которые нужны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NeighborExchangeV2](../pictures/OperatorParallelism/NeighborExchangeV2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AlltoAll**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "from mindspore.communication import init\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import numpy as np\n",
    "\n",
    "class Net(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.all_to_all = ops.AlltoAll(split_count = 8, split_dim = -2, concat_dim = -1)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.all_to_all(x)\n",
    "        return out\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE, device_target='Ascend')\n",
    "init()\n",
    "net = Net()\n",
    "rank_id = int(os.getenv(\"RANK_ID\"))\n",
    "input_x = ms.Tensor(np.ones([1, 1, 8, 1]) * rank_id, dtype = ms.float32)\n",
    "output = net(input_x)\n",
    "print(output)\n",
    "\"\"\"\n",
    "мы используем оператор AlltoAll для обмена данными с 8 картами.\n",
    "Разрезаем тензор на карте по 2 размерности с конца.\n",
    "Затем отправляем данные о срезе на другие карты по порядку, а также получаем данные от других карт\n",
    "и сшиваем их по 1 размерности с конца. Наконец, каждая карта выводит сшитые данные.\n",
    "Должно получиться такое: [[[[0. 1. 2. 3. 4. 5. 6. 7.]]]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Операция `AlltoAll` разбивает входные данные на определенное количество блоков по определенной размерности и отправляет их на другие карты по\n",
    "порядку, одновременно получая входные данные с других карт и объединяя данные по определенной размерности по порядку. Например, на приведенном ниже\n",
    "рисунке тензор разрезается на 5 частей по 1-й размерности, одновременно получая данные из других карт и объединяя их по 2-й размерности, и, наконец, выводя переключенные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AlltoAll](../pictures/OperatorParallelism/AlltoAll.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Еще примеры, связанные с операторами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `Z=(X*W)*V`\n",
    "\n",
    "Предположим, что сначала были разделены именно input данные. Тогда для их сбори применяется оператор `AllGather`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AllGather](../pictures/Sample1-Dictributed_Transformation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующем примере, наоборот используется model parallel. Для сборки и разделения, соответственно, используется оператор `AlltoAll`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt_all](../pictures/Sample2-Distributed_Transformation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последнем примере у нас между операциями с размерностями все хорошо. Однако затем необходимо уменьшить размерность. Для этого применяется оператор `AllReduce`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AllReduce](../pictures/Sample3-Distributed_Transformation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$\\underline{\\text{В MindSpore 2.2.14 планировщик 1F1B}}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "При большом количестве устройств кластера, если используется только **operator parallelism**, требуется обмен данными через область обмена данными всего кластера, что может сделать обмен данными неэффективным и, следовательно, снизить общую производительность. Конвейерный параллелизм может разделить структуру нейронной сети на несколько этапов, и каждый этап выполняется в определенной части устройства, что ограничивает область коллективного взаимодействия этой частью устройства, в то время как на промежуточном этапе используется двухточечная связь. \n",
    "\n",
    "**Базовый принцип**. Параллельный конвейер — это разделение операторов в нейронной сети на несколько этапов, а затем сопоставление этапов с разными устройствами, чтобы разные устройства могли вычислять разные части нейронной сети. Сеть из 4 слоев MatMul разбивается на 4 этапа и распределяется по 4 устройствам. При прямых вычислениях каждая машина отправляет результат следующей машине через оператора связи после вычисления MatMul на машине, и в это же время следующая машина получает (Receive) результат MatMul предыдущей машины через оператора связи, и начинает рассчитывать MatMul на машине; При обратном расчете, после того как градиент последней машины вычислен, результат отправляется предыдущей машине, и в то же время предыдущая машина получает результат градиента последней машины и начинает вычислять обратный результат текущей машины.\n",
    "\n",
    "![piepline_parallelism](../pictures/Piepline_parallelism-basic_principe.png)\n",
    "\n",
    "Простое разделение модели на несколько устройств не приведет к повышению производительности, поскольку в линейной структуре модели одновременно работает только одно устройство, в то время как другие устройства ожидают, что приводит к пустой трате ресурсов. Чтобы повысить эффективность, параллельный конвейер дополнительно делит малую партию (MiniBatch) на более мелкие микропакеты (MicroBatch) и принимает последовательность выполнения конвейера в микропакете, чтобы достичь цели повышения эффективности\n",
    "\n",
    "**GPipe schreduler**.Малые партии разрезаются на 4 микропакета, а 4 микропакета выполняются на 4 группы, образуя конвейер. Для обновления параметров используется градиентная агрегация микропартии, где каждое устройство только хранит и обновляет параметры соответствующей группы. где порядковый номер белого цвета представляет индекс микропартии.\n",
    "\n",
    "![GPipe](../pictures/Pipeline_parallelism-GPipe.png)\n",
    "\n",
    "**1F1B schreduler**.В параллельной реализации конвейера MindSpore порядок выполнения был скорректирован для лучшего управления памятью. Обратный микропакет с номером 0 выполняется сразу после его прямого выполнения, так что память промежуточного результата микропакета с номером 0 освобождается раньше, тем самым гарантируя, что пиковое использование памяти будет ниже\n",
    "\n",
    "![1F1B](../pictures/Pipeline_parallelism-1F1B.png)\n",
    "\n",
    "**Interleaved Pipeline Schreduler**.Чтобы повысить эффективность параллелизма конвейеров и уменьшить долю простоев, компания Megatron LM предлагает новую систему параллельного планирования конвейеров под названием \"чередующийся конвейер\". Традиционный конвейерный параллелизм обычно предусматривает размещение нескольких последовательных слоев модели (например, слоев трансформера) на одной рабочей площадке. При планировании конвейера с чередованием на каждом этапе выполняются вычисления с чередованием на неперерывных слоях модели, чтобы еще больше уменьшить долю простоев с большей связью. Например, при традиционном конвейерном параллелизме каждая стадия имеет 2 слоя модели, а именно: стадия 0 имеет слои 0 и 1, стадия 1 имеет слои 2 и 3, стадия 3 имеет слои 4 и 5, а стадия 4 имеет слои 6 и 7, в то время как в конвейере с чередованием на стадии 0 есть слои 0 и 4, стадия 1 содержит слои 1 и 5, стадия 2 содержит слои 2 и 6, а стадия 3 содержит слои 3 и 7.\n",
    "\n",
    "![Intervalled+1F1B](../pictures/Pipeline_patallelism-Intervalled_and_1F1B.png)\n",
    "\n",
    "**MindStore schreduler**\n",
    "\n",
    "![MindStore](../pictures/Pipeline_parallelism-MindStore_screduler.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "import mindspore.dataset as ds\n",
    "from mindspore import nn, train\n",
    "from mindspore.communication import init\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE)\n",
    "ms.set_auto_parallel_context(parallel_mode=ms.ParallelMode.SEMI_AUTO_PARALLEL, pipeline_stages=2)\n",
    "init()\n",
    "ms.set_seed(1)\n",
    "\n",
    "class Network(nn.Cell):\n",
    "    \"\"\"Network\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Dense(28*28, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Dense(512, 512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Dense(512, 10)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        logits = self.layer3(x)\n",
    "        return logits\n",
    "\n",
    "net = Network()\n",
    "net.layer1.pipeline_stage = 0\n",
    "net.relu1.pipeline_stage = 0\n",
    "net.layer2.pipeline_stage = 1\n",
    "net.relu2.pipeline_stage = 1\n",
    "net.layer3.pipeline_stage = 1\n",
    "\n",
    "def create_dataset(batch_size):\n",
    "    \"\"\"create dataset\"\"\"\n",
    "    dataset_path = os.getenv(\"DATA_PATH\")\n",
    "    dataset = ds.MnistDataset(dataset_path)\n",
    "    image_transforms = [\n",
    "        ds.vision.Rescale(1.0 / 255.0, 0),\n",
    "        ds.vision.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "        ds.vision.HWC2CHW()\n",
    "    ]\n",
    "    label_transform = ds.transforms.TypeCast(ms.int32)\n",
    "    dataset = dataset.map(image_transforms, 'image')\n",
    "    dataset = dataset.map(label_transform, 'label')\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "data_set = create_dataset(32)\n",
    "\n",
    "optimizer = nn.SGD(net.trainable_params(), 1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_cb = train.LossMonitor()\n",
    "net_with_grads = nn.PipelineCell(nn.WithLossCell(net, loss_fn), 4)\n",
    "model = ms.Model(net_with_grads, optimizer=optimizer)\n",
    "model.train(3, data_set, callbacks=[loss_cb], dataset_sink_mode=True)\n",
    "\n",
    "\"\"\"\n",
    "В этом коде используется разделение на 4 MicroBatch. При этом используется конвеер всего из 2-х карт. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$2 \\ pipeline: \\ Dev_0(layer1,\\  relu1), \\ Dev_1(layer2,\\  relu2,\\ layer3)$$\n",
    "\n",
    "$$\n",
    "D = \\cup_{k=1}^n D_k = \\cup_{k=1}^n\\cup_{i=1}^4B_{ki} \\\\ (D_k - MiniBatch; \\ B_{ki} - MicroBatch) \n",
    "$$\n",
    "\n",
    "![SchreduleScheme](../pictures/myPictures//SchredulerScheme.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Зачем нам при конвеерном параллелизме использовать именно разделение на microbatch?** \n",
    "\n",
    "Дело в том, что, что, если мы разделим на microbatch, то у нас сразу на видеокарте будет несколько обернутных для конвеера батчей. В случае, если не делить, то нам каждый раз надо будет создавать новую обертку, что существенно может снизить нашу производительность\n",
    "\n",
    "Для доказательства этого можно провети ряд экспериментов. Ниже представлены результаты (первая цифра в кортеже показывает размер батча, вторая - количество микробатчей, через \":\" представлено время, затраченное на обучение в секундах):\n",
    "$$\n",
    "(4, 1): 193.36 \\\\\n",
    "(8, 2): 166.19 \\\\\n",
    "(16, 4): 155.26 \\\\\n",
    "(32, 8): 145.04 \\\\\n",
    "$$\n",
    "Из представленных результатов видно, что время, затраченное на обучение, уменьшается.\n",
    "\n",
    "Возникает гипотеза о том, что чем больше количество microbatch тем быстрее будет обучение. Однако, исходя из представленных результатов ниже, это не так:\n",
    "$$\n",
    "(32, 1): 52.57 \\\\\n",
    "(32, 2): 67.21 \\\\\n",
    "(32, 4): 97.68 \\\\\n",
    "(32, 8): 145.04 \\\\\n",
    "(32, 16): 275.40 \\\\\n",
    "(32, 32): 528.28 \\\\\n",
    "$$\n",
    "\n",
    "**Вывод (гипотеза):** за счет разделение на microbatch действительно уменьшается время, затрачиваемое на обучение. Однако, если MiniBatch не слишком большой, то не следует его разделять на больше, чем количество видеокарт в системе \n",
    "\n",
    "**Замечание:** Стоит также отметить, что при разделении на microbatch работа видеокарты более стабильна. Также стоит отметить, что при большом разделении, оперативная память в некоторых случаях загружалась сильнее, хотя и не очень значительно. \n",
    "\n",
    "Нерешенная вопрос: Почему растет Loss?\n",
    "\n",
    "![Loss](../pictures/myPictures/TableLoss.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении параллелизму данных или параллелизму операторов одна и та же копия параметров модели может существовать на нескольких устройствах, что позволяет оптимизатору выполнять избыточные вычисления на нескольких устройствах при обновлении этого веса. В этом случае вычисления оптимизатора могут быть распределены по нескольким устройствам за счет параллелизма оптимизатора. Его преимущества заключаются в снижении потребления статической памяти и объема вычислений в оптимизаторе\n",
    "\n",
    "**Замечание:** В режиме AUTO_PARALLEL или SEMI_AUTO_PARALLEL включается optimizer parallelism, если параметры после стратегии нарезки имеют повторяющиеся срезы между машинами, а максимальный размер фигуры делится на количество повторяющихся срезов, фреймворк сохраняет параметры как минимальные срезы и обновляет их в оптимизаторе. В этом режиме поддерживаются все оптимизаторы\n",
    "\n",
    "**Что мы хотим сделать и зачем это надо?**\n",
    "\n",
    "Традиционная параллельная модель данных хранит копии параметров модели на каждом устройстве, разрезает обучающие данные, синхронизирует информацию о градиенте после каждой итерации с помощью операторов связи и, наконец, обновляет параметры с помощью вычислений оптимизатора. Параллелизм данных, хотя и эффективен для повышения производительности обучения, не позволяет максимально эффективно использовать машинные ресурсы. Оптимизатор вводит избыточную память и вычисления, устранение этих избыточностей является точкой оптимизации, на которой следует сосредоточиться.\n",
    "\n",
    "В обучающей итерации параллелизм данных вводит операцию связи для синхронизации градиентов по нескольким карточкам для сбора градиентов параметров, созданных различными выборками на каждой карте. Поскольку параллелизм модели не используется, операции оптимизатора на каждой карте фактически обновляются на основе одних и тех же параметров и в том же направлении. Основная идея устранения избыточности оптимизатора заключается в том, чтобы распределить эту память и вычисления по картам для достижения прироста памяти и производительности.\n",
    "\n",
    "**Межслойное деление**. Одной из групп весов является межслойное деление параметров и градиентов внутри оптимизатора, а общий поток обучения показан на рисунке 1. Параметры и градиенты группируются на различных картах для обновления, а затем обновленные веса распространяются между устройствами с помощью операции коммуникационной трансляции. Прирост памяти и производительности решения зависит от группы с наибольшей долей параметров. Когда параметры разделены поровну, теоретические положительные выигрыши равны (N-1)/N времени выполнения оптимизатора и динамической памяти и (N-1)/N объема памяти для параметров состояния оптимизатора, где N обозначает количество устройств. А отрицательное преимущество — это время связи, которое наступает при совместном использовании весов сети.\n",
    "\n",
    "![Inner-layer](../pictures/Optimizer_parallelism-inner-layer.png)\n",
    "\n",
    "\n",
    "**Внутрислойное деление (Ее использует MindSpore)**. Еще один способ реализации нарезки параметров — это внутрислойное разделение параметров, и для каждого параметра берется соответствующий срез и градиент в соответствии с номером устройства. После обновления параметров и градиентов вызывается операция агрегации связи для совместного использования параметров между устройствами. Преимущество этой схемы в том, что она естественно поддерживает балансировку нагрузки, т.е. количество параметров и вычислений согласовано на каждой карте, а недостаток в том, что форма параметра должна быть кратна количеству устройств. Теоретические преимущества этой схемы согласуются с группировкой параметров, и в систему были внесены следующие усовершенствования с целью расширения преимуществ.\n",
    "\n",
    "Во-первых, разделение весов в сети может еще больше уменьшить статическую память. Однако для этого также требуется выполнить операцию с общим весом в конце итерации перед прямым началом следующей итерации, гарантируя, что исходная форма тензора останется неизменной после перехода к прямым и обратным операциям. Кроме того, основным проигрышем от параллельной работы оптимизатора является время связи общих весов, которое может принести выигрыш в производительности, если мы сможем его уменьшить или скрыть. Одним из преимуществ перекрестной итерации связи является то, что операции связи могут выполняться вперемежку с прямой сетью путем объединения операторов связи в соответствующие группы, тем самым максимально скрывая затраты времени на связь. Затраты времени на общение также связаны с объемом общения. Для сети со смешанной точностью, если мы сможем использовать связь fp16, объем связи уменьшится вдвое по сравнению с fp32.\n",
    "\n",
    "![MindStore](../pictures/Optimizer_parallelism-MindStore.png)\n",
    "\n",
    "**Замечание:** Что такое перерестаня итерация?\n",
    "\n",
    "**Перекрестная итерация** (cross-iteration) представляет собой технику, которая позволяет различным частям нейронной сети обмениваться информацией на протяжении процесса обучения. Это особенно полезно при работе с большими и сложными моделями, которые разбиваются на несколько частей для параллельной обработки.\n",
    "\n",
    "Как работает перекрестная итерация?\n",
    "1) Разбиение сети: Нейронная сеть делится на несколько более мелких подсетей.\n",
    "2) Параллельная обработка: Каждая подсеть обрабатывает свою часть данных независимо.\n",
    "3) Обмен информацией: После определенного числа итераций (или эпох) обучения, подсети обмениваются информацией о своих текущих весах или активациях.\n",
    "4) Обновление весов: На основе полученной информации, каждая подсеть обновляет свои веса, чтобы лучше согласовать свою работу с другими подсетями.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![OptimiserScheme](../pictures/myPictures/OptimiserScheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "import mindspore.dataset as ds\n",
    "from mindspore import nn\n",
    "from mindspore.communication import init\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE)\n",
    "ms.set_auto_parallel_context(parallel_mode=ms.ParallelMode.SEMI_AUTO_PARALLEL, enable_parallel_optimizer=True)\n",
    "init()\n",
    "ms.set_seed(1)\n",
    "\n",
    "class Network(nn.Cell):\n",
    "    \"\"\"Network\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Dense(28*28, 512)\n",
    "        self.layer2 = nn.Dense(512, 512)\n",
    "        self.layer3 = nn.Dense(512, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "        logits = self.layer3(x)\n",
    "        return logits\n",
    "\n",
    "net = Network()\n",
    "net.layer1.set_comm_fusion(0)\n",
    "net.layer2.set_comm_fusion(1)\n",
    "net.layer3.set_comm_fusion(2)\n",
    "\n",
    "def create_dataset(batch_size):\n",
    "    \"\"\"create dataset\"\"\"\n",
    "    dataset_path = os.getenv(\"DATA_PATH\")\n",
    "    dataset = ds.MnistDataset(dataset_path)\n",
    "    image_transforms = [\n",
    "        ds.vision.Rescale(1.0 / 255.0, 0),\n",
    "        ds.vision.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "        ds.vision.HWC2CHW()\n",
    "    ]\n",
    "    label_transform = ds.transforms.TypeCast(ms.int32)\n",
    "    dataset = dataset.map(image_transforms, 'image')\n",
    "    dataset = dataset.map(label_transform, 'label')\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "data_set = create_dataset(32)\n",
    "optimizer = nn.SGD(net.trainable_params(), 1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def forward_fn(data, target):\n",
    "    \"\"\"forward propagation\"\"\"\n",
    "    logits = net(data)\n",
    "    loss = loss_fn(logits, target)\n",
    "    return loss, logits\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, net.trainable_params(), has_aux=True)\n",
    "\n",
    "@ms.jit\n",
    "def train_step(inputs, targets):\n",
    "    \"\"\"train_step\"\"\"\n",
    "    (loss_value, _), grads = grad_fn(inputs, targets)\n",
    "    optimizer(grads)\n",
    "    return loss_value\n",
    "\n",
    "for epoch in range(10):\n",
    "    i = 0\n",
    "    for image, label in data_set:\n",
    "        loss_output = train_step(image, label)\n",
    "        if i % 10 == 0:\n",
    "            print(\"epoch: %s, step: %s, loss is %s\" % (epoch, i, loss_output))\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
