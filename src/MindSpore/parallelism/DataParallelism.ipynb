{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataParallel](../pictures/DataParallel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Вызывается `mindstore.communication.init` для инициализации коммуникационных ресурсов\n",
    "2) Данные делятся на батчи (шарды), каждый шард имеет две переменные:`num_shards` и `shard_id`. По этим параметрам и происходят все операции по разделению датасета.\n",
    "3) Изначально на всех частях инициализируются одинаковые значения. Это нужно для того, чтобы обеспечить синхронное обучение. Чтобы транслировать значения весов на разные ноды необходимо включить  parameter_broadcast\n",
    "4) После этого со всех узлов собираются градиенты и происходит их агрегация. Для этого существует оператор `AllReduce`. У него есть функция mean. При ее включении происходит усреднение значений, однако существенно понижается производитльность\n",
    "5) Происходит обновление параметров, из-за того, что параметр градиента усреднен и при этом начальные значения тоже одинаковы, то обновленные значения будут тоже одинаковы.  Если в сети задействована операция reduce над выборками, вывод сети может отличаться. Это определяется атрибутом сегментирования параллелизма данных."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
